
% ===========================================================================
% Title:
% ---------------------------------------------------------------------------
% to create Type I fonts type "dvips -P cmz -t letter <filename>"
% ===========================================================================
\documentclass[11pt]{article}       %--- LATEX 2e base
\usepackage{latexsym}               %--- LATEX 2e base
%---------------- Wide format -----------------------------------------------
\textwidth=6in \textheight=9in \oddsidemargin=0.25in
\evensidemargin=0.25in \topmargin=-0.5in
%--------------- Def., Theorem, Proof, etc. ---------------------------------
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{property}{Property}
\newtheorem{observation}{Observation}
\newtheorem{fact}{Fact}
\newenvironment{proof}           {\noindent{\bf Proof.} }%
                                 {\null\hfill$\Box$\par\medskip}
%--------------- Algorithm --------------------------------------------------
\newtheorem{algX}{Algorithm}
\newenvironment{algorithm}       {\begin{algX}\begin{em}}%
                                 {\par\noindent --- End of Algorithm ---
                                 \end{em}\end{algX}}
\newcommand{\step}[2]            {\begin{list}{}
                                  {  \setlength{\topsep}{0cm}
                                     \setlength{\partopsep}{0cm}
                                     \setlength{\leftmargin}{0.8cm}
                                     \setlength{\labelwidth}{0.7cm}
                                     \setlength{\labelsep}{0.1cm}    }
                                  \item[#1]#2    \end{list}}
                                 % usage: \begin{algorithm} \label{xyz}
                                 %        ... \step{(1)}{...} ...
                                 %        \end{algorithm}
%--------------- Figures ----------------------------------------------------
\usepackage{graphicx}

\newcommand{\includeFig}[3]      {\begin{figure}[htb] \begin{center}
                                 \includegraphics
                                 [width=4in,keepaspectratio] %comment this 
                                                   %line to disable scaling
                                 {#2}\caption{\label{#1}#3} \end{center} 
                                 \end{figure}}
                                 % usage: \includeFig{label}{file}{caption}


% ===========================================================================
\begin{document}
% ===========================================================================

% ############################################################################
% Title
% ############################################################################

\title{LITERATURE REVIEW: \\
  Parallel Metropolis-Hastings Algorithms
}


% ############################################################################
% Author(s) (no blank lines !)
\author{
% ############################################################################
Boyan Bejanov\\
{\em bbejanov@bankofcanada.ca}
% ############################################################################
} % end-authors
% ############################################################################

\maketitle



% ############################################################################
\section{Introduction} \label{intro}
% ############################################################################

The Monte Carlo methods (MC) are a class of numerical integration techniques,
where the integral is interpreted as the expected value of some function of
some random variable.  The expectation can be statistically estimated from a
sample drawn from the same distribution as the underlying random variable and
this estimate serves as the numerical approximation of the integral.  Needless
to say, the MC methods are also applicable to problems other than numerical
integration, so long as they can be reduced to the evaluation of an expected
value.  

The successful application of MC relies on the availability of numerical
techniques for simulation of random samples from a distribution, which is given
by its probability density function (pdf).  We will denote this \emph{target}
pdf by $\pi(x)$.  It is always assumed that a stream of independent random
numbers with uniform distribution in the interval $(0,1)$ is available without
ado.  For some of the other common probability distributions there are direct
methods of simulation, which perform some computation on the uniform random
numbers, transforming them into random numbers of the desired distribution.
However, these techniques are limited to special cases.  One of the most
important general sampling technique is the Acceptance-Rejection sampling (AR).
Each iteration of the AR goes in two steps.  We first simulate a random number,
$X$, from some other distribution, which can be simulated by an already known
method.  We call this distribution \emph{proposal} and denote its pdf by
$q(x)$.  In the second step, we simulate a uniform random number and compare it
to the adjusted ratio of the target and proposal densities.  Based on this
comparison, we either accept $X$ as a random number from $\pi$, or we reject
and discard it.  The AR method is embarrassingly parallel, since multiple
random numbers can be simulated on multiple processors simultaneously.  In
addition, it produces a sample of independent random numbers, which can be used
directly in an MC method.  However, its applicability is limited to the cases
where $\pi(x)$ is given explicitly by a known formula.  Even then, the
computational efficiency of AR (as measured by the acceptance rate) depends on
the choice of the proposal, $q(x)$, and a tight estimate of the adjustment
constant in the AR test, both of which can require some non-trivial
mathematical derivations, especially for multivariate distributions.  

The method of choice in the cases of a multivariate distribution of high
dimension, or when the formula for the target pdf is too complicated, or when
the target pdf can only be computed numerically, is the Markov Chain Monte
Carlo method (MCMC).  A Markov Chain is a process, which is described by a
\emph{state space}, i.e. the set of all possible values the process can take,
and a transition rule, which may depend only on the current state, but not any
earlier ones. It is known from the theory of Markov chains that, if certain
conditions are satisfied, the process has an \emph{invariant distribution} and
the distributions of successive states converge to the invariant distribution.
In the MCMC method, we construct a transition rule, such that the resulting
Markov chain has an invariant distribution, and this invariant distribution is
exactly $\pi(x)$.  The initial part of the chain, before the distribution of
states gets close enough to the invariant distribution, is known as
\emph{burn-in} and is discarded.  The remaining chain can be used as the random
sample in a Monte Carlo method, although with the caveat that it is not an
independent random sample, so the auto-correlation of the process must be taken
into account.  

The AR, MCMC and other methods for simulation of random variables, as well as
the underlying mathematical theories, can be found in \cite{ross.simulation}.


The Metropolis-Hastings algorithm (M-H) combines AR and MCMC.  Effectively, it
is a recipe for constructing the transition rule of a Markov chain given its
desired invariant distribution.  Once again, we have a proposal distribution,
however this time the proposal distribution depends on the current state of the
chain, i.e. $q=q(x;y)$. The good news is that the accept-reject test is a ratio
of the values of $q$ and $\pi$ at the current and the proposed points with no
adjustment constants to be derived in advance.  If the proposed point is
accepted, then it becomes the next state of the chain, otherwise the next state
is equal to the current state, i.e. no points are discarded as it was the case
in the AR sampling method.  An intuitive and self-contained presentation of the
Metropolis-Hastings method can be found in \cite{understanding.MH}.

Other than Monte Carlo type estimations of expected values, the M-H is a
general method for simulating random samples from distributions that are
otherwise impossible to simulate.  It is particularly popular for Bayesian
analysis of complex stochastic models.  Such models always involve a number of
parameters, which rarely can be derived from first principles.  More
frequently, the parameters are estimated from observed data using
maximum-likelihood, or some other methods of statistical estimation.  When the
model is sufficiently complex, the usual inference based on confidence
intervals for the estimated parameters is impossible to derive.  In such cases,
the approach of Bayesian statistics is to consider the parameters as random
variables,  simulate a sample from their joint distribution, and use this
sample to infer the properties of the distribution that are of interest.

The specific focus in this project is the application of M-H to Bayesian
inference of large Dynamic Stochastic General Equilibrium models (DSGE), which
are used in the field of macro-economics (\cite{strid2010adaptive}).  The
likelihood function is computed using a Kalman filter, which can be
computationally very expensive, especially in the nonlinear case.  Therefore,
when considering various methods, we will keep in mind the (simplifying)
assumption that the evaluation of $\pi(x)$ is much more time consuming than all
the other computations in a single step of the Markov chain (such as the
computation of $q(x,y)$, simulation from $q(x,y)$, individual arithmetic
operations). 

The objectives of this project include
\begin{itemize}
\item Survey the existing methods and evaluate them.
\item Identify the most promising method, for the particular setting we have, and implement it.
\item Investigate the benefits of parallelisation in terms of theoretical and
     practically achieved speedup.
\item Consider the question of P-completeness of the M-H algorithm.
\end{itemize}


% ############################################################################
\section{Literature Review} \label{litrev}
% ############################################################################

The search for parallel algorithms for M-H and other MCMC techniques has received
much attention from the computational statistics community as well as from 
researchers in various fields where MCMC finds real-world applications.  
Unfortunately, there seems to be little attention given to this question 
in the world of computer science.

In \cite{solonen2012efficient} the authors propose an \emph{adaptive} M-H
method for estimation of a climate model, where multiple Markov chains are
simulated in parallel.  In an adaptive MCMC algorithm, the computed values of
the target pdf are used to construct a better proposal distribution.  Each
chain must undergo its own burn-in, therefore the time before the algorithm
starts yielding useful output is the same as in the sequential case.  This
greatly limits the gain in speedup due to parallelisation.  However, the
periodic updates to the proposal distribution in each chain use the values of
the target density produced by all chains.  This way the algorithm produces
higher quality proposal compared to the sequential version, thus improving the
\emph{statistical efficiency} of the chain.

Another recent application of parallel MCMC is presented in
\cite{wu2012parallel} in the context of Bayesian models of animal breeding and
genetics.  Here the authors also consider multiple Markov chains running in
parallel and acknowledge that this is only applicable to single-parameter
models and simpler models with few parameters.  In the case of more complex
models, they use parallel computation of $\pi(x)$ by leveraging specific
properties of the 
particular model they consider.

A modified M-H algorithm is presented in \cite{miller2010markov}.  It simulates
a single Markov chain with improved  statistical properties by considering
multiple proposal points at each step.  The proposals are computed in  parallel
and one of them is randomly selected to be the next state.  This allows for
better coverage of the state space, i.e. reduced burn-in time.  However, the
time for computing one step is the same as in the sequential 
M-H algorithm.


In \cite{vanderwerken2013parallel}, the authors propose a parallel MCMC method
which is only applicable to numerical integration.  The state space is
partitioned into disjoint regions and the total integral is evaluated as the
sum of the integrals over the individual regions. A separate Markov chain is
simulated for each region in parallel.  The clever innovation of this method is
that it allows the chains to leave their respective regions and are recombined
afterwards.  This considerably simplifies previous methods using partitioning,
which must contain the individual chains within their regions.  Unfortunately,
this method is not applicable in our case, since it only computes the
expectation, but doesn't produce a random sample.

In general the parallel MCMC methods can be divided into methods using multiple
independent chains that are simulated in parallel and methods that simulate a
single chain in parallel.  All of the methods discussed so far are in the first
category.  The paper \cite{guo2012parallel} contains a recent and detailed
overview of parallel MCMC methods based on multiple chains.

The single chain parallel methods can be further subdivided into \emph{within
draw} and \emph{between draw} parallelisation, as suggested in
\cite{strid2010efficient}.  In the former class of methods multiple processors
collaborate on a single computation of the target density.  Clearly this
approach is problem-specific.  The between draw parallel methods rely on
pre-computing the values of the target density at multiple proposed points  in
parallel ahead of time.  Several accept-reject iterations are then carried out
sequentially as usual.  

regeneration times

independence proposal

Pre-fetching

\cite{byrd2008reducing}






% ############################################################################
% Bibliography
% ############################################################################
\bibliographystyle{plain}
\bibliography{my-bibliography}     %loads my-bibliography.bib

% ============================================================================
\end{document}
% ============================================================================
